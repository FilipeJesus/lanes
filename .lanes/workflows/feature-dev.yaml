name: feature-dev
description: Plan and implement a new feature

agents:
  coder:
    description: Writes code to implement features

  test-engineer:
    description: Runs tests and fixes failures

  code-reviewer:
    description: Reviews code for quality

loops:
  feature_development:
    - id: implement
      agent: coder
      instructions: |
        Implement: {task.title}
        Description: {task.description}

        1. Read relevant files to understand context
        2. Plan the implementation approach
        3. Write the code
        4. Verify it compiles

        Do NOT run tests yet - that will be handled in the next step.

    - id: test
      agent: test-engineer
      instructions: |
        Run tests for: {task.title}

        1. Run the existing test suite
        2. Identify any failing tests
        3. Fix any test failures
        4. Ensure all tests pass
      on_fail: retry

    - id: review
      agent: code-reviewer
      instructions: |
        Review implementation of: {task.title}

        Check for:
        1. Security vulnerabilities
        2. Proper error handling
        3. Code quality and patterns
        4. Edge cases and potential bugs
        5. Consistency with existing code style

    - id: resolution
      instructions: |
        Check the review of: {task.title}

        1. Read the review feedback
        2. Identify any critical issues raised
        3. Address critical issues if present
        4. Mark the task as complete

steps:
  - id: plan
    type: action
    instructions: |
      Analyze the goal and break it into discrete tasks, importantly a test should NOT
      BE considered a task as testing should be done in the same step as feature development.
      ONLY CONSIDER testing to be a task if the user explicitly requests a test creation feature.
      Verification should NOT be considered a task, this should be done during standard reviews.

      Consider:
      1. What are the individual features or changes needed?
      2. What are the dependencies between tasks?
      3. What is the optimal order of implementation?
      4. Review your task list and combine tasks that should be done together.
         A task should represent a complete, testable unit of functionality.

      Document your analysis before proceeding.

      IMPORTANT: Do NOT call workflow_set_tasks in this step - that happens in the next step.
      When done analyzing, call workflow_advance with your analysis summary.

  - id: define_tasks
    type: action
    instructions: |
      For each task identified in the planning phase, define:
      - id: A unique identifier (e.g., 'add-login-form', 'fix-validation')
      - title: A clear, concise title
      - description: Detailed description of what needs to be done

      Call workflow_set_tasks('feature_development', tasks) when done.

      IMPORTANT: The loop is named 'feature_development' - use exactly this name.
      CRITIAL: Do NOT include testing as a task unless explicitly requested by the user.

  - id: feature_development
    type: loop

  - id: final_review
    type: action
    agent: code-reviewer
    instructions: |
      Review the implementation as a whole.

      Check for:
      1. Consistency across all changes
      2. Any missed requirements
      3. Integration issues between features
      4. Overall code quality
      5. Documentation completeness

  - id: final_resolution
    type: action
    instructions: |
      Address any issues from the final review.

      1. Review the feedback from the final review
      2. Make any necessary adjustments
      3. Prepare the changes for commit
      4. Summarize what was accomplished
